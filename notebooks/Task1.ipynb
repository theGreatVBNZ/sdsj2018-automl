{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from utils import load, transform_datetime_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_features(df_x):\n",
    "    constant_columns = [\n",
    "        col_name\n",
    "        for col_name in df_x.columns\n",
    "        if df_x[col_name].nunique() == 1\n",
    "    ]\n",
    "    return constant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df_x, cols):\n",
    "    return df_x.drop(constant_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_for_encoding(df_x, max_unique=20):\n",
    "    categorical = {}\n",
    "    for col_name in list(df_x.columns):\n",
    "        col_unique_values = df_x[col_name].unique()\n",
    "        if 2 < len(col_unique_values) <= max_unique:\n",
    "            categorical[col_name] = col_unique_values\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df_x, categorical):\n",
    "    df_dummies = pd.DataFrame()\n",
    "    for col_name, unique_values in categorical.items():\n",
    "        for unique_value in unique_values:\n",
    "            df_dummies[f'onehot_{col_name}={unique_value}'] = (df_x[col_name] == unique_value).astype(int)\n",
    "    return pd.concat([df_x, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missings(df_x):\n",
    "    columns_with_missings = df_x.columns[df_x.isna().any()].tolist()\n",
    "    return columns_with_missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missings(df_x, columns):\n",
    "    df_x = df_x.copy()\n",
    "    for col_name in columns:\n",
    "        df_x[col_name].fillna(-1, inplace=True)\n",
    "    return df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_numeric_columns(df_x):\n",
    "    numeric_columns = [\n",
    "        col_name\n",
    "        for col_name in df_x.columns\n",
    "        if col_name.startswith('number') or col_name.startswith('onehot')\n",
    "    ]\n",
    "    return numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_columns(df_x, columns):\n",
    "    return df_x[columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaler(df_x):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_x)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df_x, scaler):\n",
    "    return pd.DataFrame(data=scaler.transform(df_x), columns=df_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df_transformed, model):\n",
    "    predictions = model.predict(df_transformed)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура\n",
    "Функции деляться на добытчиков (miner) и преобразователей (transformer). Добытчик извлекает правила преобразования на основе обучающего множества. Преобразователь применяет правила, извлеченные добытчиком к данным. Такая архитектура позволяет безболезненно переносить модели с x_train на x_test, даже если в данных имеются весомые различия (например x_test не имеет каких-то уровней категориальных переменных, что могло бы повлечь ошибки one-hot-encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(df_x, target):\n",
    "    pipeline = []\n",
    "\n",
    "    constant_columns = constant_features(df_x)\n",
    "    df_x = drop_columns(df_x, cols=constant_columns)\n",
    "    pipeline.append(partial(drop_columns, cols=constant_columns))\n",
    "\n",
    "    categorical = select_for_encoding(df_x, max_unique=20)\n",
    "    df_x = one_hot_encoding(df_x, categorical=categorical)\n",
    "    pipeline.append(partial(one_hot_encoding, categorical=categorical))\n",
    "\n",
    "    columns_with_missings = find_missings(df_x)\n",
    "    df_x = fill_missings(df_x, columns=columns_with_missings)\n",
    "    pipeline.append(partial(fill_missings, columns=columns_with_missings))\n",
    "\n",
    "    numeric_columns = select_numeric_columns(df_x)\n",
    "    df_x = keep_columns(df_x, columns=numeric_columns)\n",
    "    pipeline.append(partial(keep_columns, columns=numeric_columns))\n",
    "\n",
    "    scaler = create_scaler(df_x)\n",
    "    df_x = scale(df_x, scaler)\n",
    "    pipeline.append(partial(scale, scaler=scaler))\n",
    "    \n",
    "    df_transformed = df_x\n",
    "    \n",
    "    model = Ridge()\n",
    "    model.fit(df_transformed, target)\n",
    "    predictions = make_predictions(df_transformed, model)\n",
    "    pipeline.append(partial(make_predictions, model=model))\n",
    "    return pipeline, df_transformed, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x, target = load(1, 'train')\n",
    "_, y_test = load(1, 'test-target')\n",
    "x_test, _ = load(1, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(df_x, target, test_size=.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, x_train, train_predictions = create_pipeline(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_x, pipeline):\n",
    "    result = df_x\n",
    "    for transform in pipeline:\n",
    "        result = transform(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(y_true, y_pred):\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5.491683645412526, \n",
      "Validation RMSE: 6.4206762174510885, \n",
      "Test RMSE: 11.131148284326269\n"
     ]
    }
   ],
   "source": [
    "df_x, target = load(1, 'train')\n",
    "_, y_test = load(1, 'test-target')\n",
    "x_test, _ = load(1, 'test')\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(df_x, target, test_size=.2, random_state=123)\n",
    "\n",
    "pipeline, x_train, train_predictions = create_pipeline(x_train, y_train)\n",
    "train_rmse = assess(y_train, train_predictions)\n",
    "\n",
    "valid_predictions = predict(x_valid, pipeline)\n",
    "valid_rmse = assess(y_valid, valid_predictions)\n",
    "\n",
    "test_predictions = predict(x_test, pipeline)\n",
    "test_rmse = assess(y_test, test_predictions)\n",
    "\n",
    "print(f'Train RMSE: {train_rmse}, \\nValidation RMSE: {valid_rmse}, \\nTest RMSE: {test_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
