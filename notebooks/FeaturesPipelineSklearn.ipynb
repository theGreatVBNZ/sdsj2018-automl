{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка фичей с помощью инструментов sklearn: Pipeline, FeatureUnion, ColumnTransformer, ...\n",
    "\n",
    "Фиксируем numeric и categorical columns. Ищем datetime переменные.\n",
    "\n",
    "Для datetime (каждый пункт строится независимо):\n",
    "    - выделение дней, месяцев, ...\n",
    "\n",
    "Для numeric (каждый пункт строится независимо):\n",
    "    - lag-фичи по каждой datetime переменной\n",
    "    - agg-фичи по месяцам, неделям и дням каждой datetime переменной\n",
    "\n",
    "Для categorical (каждый пункт строится независимо):\n",
    "    - dummies\n",
    "    \n",
    "Отдельный пайплайн на обработку пропусков в категориальных и числовых признаках:\n",
    "http://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from IPython.display import display\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load\n",
    "\n",
    "task = 4\n",
    "df_x, target = load(task, 'train')\n",
    "_, y_test = load(task, 'test-target')\n",
    "x_test, _ = load(task, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114130, 142)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем колонки по типам значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_columns_by_type(df_x, max_categorical_levels):\n",
    "    max_categorical_levels = 10\n",
    "    datetime_columns, numerical_columns, categorical_columns, idx_columns, single_value_columns = [], [], [], [], []\n",
    "    for col in df_x.columns:\n",
    "        column_unique_values = df_x[col].nunique()\n",
    "        if column_unique_values <= max_categorical_levels:\n",
    "            if column_unique_values == 1:\n",
    "                single_value_columns.append(col)\n",
    "            else:\n",
    "                categorical_columns.append(col)\n",
    "        elif col.startswith('datetime'):\n",
    "            datetime_columns.append(col)\n",
    "        elif col.startswith('number'):\n",
    "            numerical_columns.append(col)\n",
    "        elif col.startswith('id_') or col.endswith('_id'):\n",
    "            idx_columns.append(col)\n",
    "    return datetime_columns, numerical_columns, categorical_columns, idx_columns, single_value_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns, numerical_columns, categorical_columns, idx_columns, single_value_columns = group_columns_by_type(df_x, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделение datetime фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DatetimeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):            \n",
    "        self.created_features = None\n",
    "        \n",
    "    def transform(self, col):\n",
    "        df_datetime = pd.DataFrame()\n",
    "        col = col.apply(lambda x: self.parse_dt(x))\n",
    "        df_datetime[f'weekday_dt'] = col.apply(lambda x: x.weekday())\n",
    "        df_datetime[f'month_dt'] = col.apply(lambda x: x.month)\n",
    "        df_datetime[f'day_dt'] = col.apply(lambda x: x.day)\n",
    "        df_datetime[f'hour_dt'] = col.apply(lambda x: x.hour)\n",
    "        df_datetime[f'hour_of_week_dt'] = col.apply(lambda x: x.hour + x.weekday() * 24)\n",
    "        df_datetime[f'minute_of_day_dt'] = col.apply(lambda x: x.minute + x.hour * 60)\n",
    "        \n",
    "        if self.created_features is None:\n",
    "            self.created_features = list(df_datetime.columns)\n",
    "        else:\n",
    "            assert self.created_features == list(df_datetime.columns)\n",
    "        return df_datetime\n",
    "    \n",
    "    def fit(self, x, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def parse_dt(self, x):        \n",
    "        if isinstance(x, datetime.datetime) or isinstance(x, datetime.date):\n",
    "            return x\n",
    "        elif not isinstance(x, str):\n",
    "            return np.nan\n",
    "        elif len(x) == len('2010-01-01'):\n",
    "            return datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "        elif len(x) == len('2010-01-01 10:10:10'):\n",
    "            return datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    def get_feature_names(self):\n",
    "        return self.created_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "datetime_transformer = ColumnTransformer([\n",
    "    (col, DatetimeTransformer(), col) \n",
    "    for col in datetime_columns\n",
    "])\n",
    "\n",
    "# _x = datetime_transformer.fit_transform(df_x)\n",
    "# _features = datetime_transformer.get_feature_names()\n",
    "# pd.DataFrame(data=_x, columns=_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LagValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, by):\n",
    "        self.by = by\n",
    "        self.created_features = None\n",
    "        \n",
    "    def transform(self, df_x):\n",
    "        columns_to_shift = [col for col in df_x.columns if col != self.by]\n",
    "        df_lags = df_x.sort_values(self.by, ascending=True)\n",
    "        df_lags.drop(self.by, axis=1, inplace=True)\n",
    "        df_lags = df_lags.shift(-1)\n",
    "        df_lags.columns = [f'{col}_shift_1' for col in columns_to_shift]\n",
    "        \n",
    "        if self.created_features is None:\n",
    "            self.created_features = list(df_lags.columns)\n",
    "        else:\n",
    "            assert self.created_features == list(df_lags.columns)\n",
    "        return df_lags\n",
    "        \n",
    "    def fit(self, x, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.created_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_transformer = ColumnTransformer([\n",
    "    (col, LagValues(by=col), [col] + numerical_columns) \n",
    "    for col in datetime_columns\n",
    "])\n",
    "\n",
    "# _x = lag_transformer.fit_transform(df_x)\n",
    "# _features = lag_transformer.get_feature_names()\n",
    "# pd.DataFrame(data=_x, columns=_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feature_generator = FeatureUnion([\n",
    "    ('datetime', datetime_transformer),\n",
    "    ('lag_numeric', lag_transformer)\n",
    "], n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 ms, sys: 8.81 ms, total: 161 ms\n",
      "Wall time: 173 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.00000000e+00, 3.00000000e+00, 3.10000000e+01, ...,\n",
       "        6.66710206e-01, 9.70118879e-01, 7.63741154e-01],\n",
       "       [3.00000000e+00, 3.00000000e+00, 3.00000000e+01, ...,\n",
       "        5.40185538e-01, 4.35392339e-01, 6.73276360e-01],\n",
       "       [5.00000000e+00, 4.00000000e+00, 1.50000000e+01, ...,\n",
       "        8.35761686e-01, 3.09176040e-01, 3.40171207e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 3.00000000e+00, 2.70000000e+01, ...,\n",
       "        7.77300436e-01, 2.28450957e-03, 7.54403534e-01],\n",
       "       [3.00000000e+00, 4.00000000e+00, 2.00000000e+01, ...,\n",
       "        5.60477365e-01, 4.30710881e-01, 4.47019213e-01],\n",
       "       [3.00000000e+00, 3.00000000e+00, 9.00000000e+00, ...,\n",
       "                   nan,            nan,            nan]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "feature_generator.fit_transform(df_x.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 135 ms, sys: 6.36 ms, total: 141 ms\n",
      "Wall time: 145 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.00000000e+00, 2.00000000e+00, 2.40000000e+01, ...,\n",
       "        2.47276764e-04, 3.55766894e-01, 8.83302774e-01],\n",
       "       [1.00000000e+00, 8.00000000e+00, 2.90000000e+01, ...,\n",
       "        3.30443470e-01, 5.75818984e-01, 7.27896819e-01],\n",
       "       [0.00000000e+00, 5.00000000e+00, 2.90000000e+01, ...,\n",
       "        3.76982815e-02, 4.98714372e-01, 5.85553918e-02],\n",
       "       ...,\n",
       "       [5.00000000e+00, 5.00000000e+00, 6.00000000e+00, ...,\n",
       "        9.61862674e-01, 5.40502857e-01, 3.69302317e-01],\n",
       "       [4.00000000e+00, 6.00000000e+00, 1.60000000e+01, ...,\n",
       "        7.62253520e-01, 5.04556728e-01, 8.62314438e-01],\n",
       "       [2.00000000e+00, 4.00000000e+00, 1.20000000e+01, ...,\n",
       "                   nan,            nan,            nan]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "feature_generator.transform(df_x.tail(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
