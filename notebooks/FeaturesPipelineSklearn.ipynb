{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка фичей с помощью инструментов sklearn: Pipeline, FeatureUnion, ColumnTransformer, ...<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer<br>\n",
    "http://scikit-learn.org/stable/modules/compose.html<br>\n",
    "http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html<br>\n",
    "http://michelleful.github.io/code-blog/2015/06/20/pipelines/<br>\n",
    "\n",
    "Фиксируем numeric и categorical columns. Ищем datetime переменные.\n",
    "\n",
    "Для datetime (каждый пункт строится независимо):\n",
    "    - выделение дней, месяцев, ...\n",
    "\n",
    "Для numeric (каждый пункт строится независимо):\n",
    "    - lag-фичи по каждой datetime переменной\n",
    "    - agg-фичи по месяцам, неделям и дням каждой datetime переменной\n",
    "\n",
    "Для categorical (каждый пункт строится независимо):\n",
    "    - dummies\n",
    "   \n",
    "Заполняем пропуски: http://scikit-learn.org/stable/modules/impute.html#impute\n",
    "    \n",
    "Отдельный пайплайн на обработку пропусков в категориальных и числовых признаках:<br>\n",
    "http://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitrymikhailovich_/cnt/sdsj2018-automl/.direnv/python-3.6.3/lib/python3.6/site-packages/lightgbm/__init__.py:45: FutureWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS will be built by the Apple Clang compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you won't need to install the gcc compiler anymore.\n",
      "Instead of that, you'll need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from IPython.display import display\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load\n",
    "\n",
    "task = 4\n",
    "df_x, target = load(task, 'train')\n",
    "_, y_test = load(task, 'test-target')\n",
    "x_test, _ = load(task, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114130, 142)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем колонки по типам значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_columns_by_type(df_x, max_categorical_levels):\n",
    "    max_categorical_levels = 10\n",
    "    datetime_columns, numerical_columns, categorical_columns, idx_columns, single_value_columns = [], [], [], [], []\n",
    "    for col in df_x.columns:\n",
    "        column_unique_values = df_x[col].nunique()\n",
    "        if column_unique_values <= max_categorical_levels:\n",
    "            if column_unique_values == 1:\n",
    "                single_value_columns.append(col)\n",
    "            else:\n",
    "                categorical_columns.append(col)\n",
    "        elif col.startswith('datetime'):\n",
    "            datetime_columns.append(col)\n",
    "        elif col.startswith('number'):\n",
    "            numerical_columns.append(col)\n",
    "        elif col.startswith('id_') or col.endswith('_id'):\n",
    "            idx_columns.append(col)\n",
    "    return datetime_columns, numerical_columns, categorical_columns, idx_columns, single_value_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns, numerical_columns, categorical_columns, idx_columns, single_value_columns = group_columns_by_type(df_x, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделение datetime фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer\n",
    "# http://scikit-learn.org/stable/modules/compose.html\n",
    "# http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "# http://michelleful.github.io/code-blog/2015/06/20/pipelines/\n",
    "\n",
    "import datetime\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DatetimeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):            \n",
    "        self.created_features = None\n",
    "        \n",
    "    def transform(self, col):\n",
    "        df_datetime = pd.DataFrame()\n",
    "        col = col.apply(lambda x: self.parse_dt(x))\n",
    "        df_datetime[f'weekday_dt'] = col.apply(lambda x: x.weekday())\n",
    "        df_datetime[f'month_dt'] = col.apply(lambda x: x.month)\n",
    "        df_datetime[f'day_dt'] = col.apply(lambda x: x.day)\n",
    "        df_datetime[f'hour_dt'] = col.apply(lambda x: x.hour)\n",
    "        df_datetime[f'hour_of_week_dt'] = col.apply(lambda x: x.hour + x.weekday() * 24)\n",
    "        df_datetime[f'minute_of_day_dt'] = col.apply(lambda x: x.minute + x.hour * 60)\n",
    "        \n",
    "        if self.created_features is None:\n",
    "            self.created_features = list(df_datetime.columns)\n",
    "        else:\n",
    "            assert self.created_features == list(df_datetime.columns)\n",
    "        return df_datetime\n",
    "    \n",
    "    def fit(self, x, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def parse_dt(self, x):        \n",
    "        if isinstance(x, datetime.datetime) or isinstance(x, datetime.date):\n",
    "            return x\n",
    "        elif not isinstance(x, str):\n",
    "            return np.nan\n",
    "        elif len(x) == len('2010-01-01'):\n",
    "            return datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "        elif len(x) == len('2010-01-01 10:10:10'):\n",
    "            return datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    def get_feature_names(self):\n",
    "        return self.created_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "datetime_transformer = ColumnTransformer([\n",
    "    (col, DatetimeTransformer(), col) \n",
    "    for col in datetime_columns\n",
    "])\n",
    "\n",
    "# _x = datetime_transformer.fit_transform(df_x)\n",
    "# _features = datetime_transformer.get_feature_names()\n",
    "# pd.DataFrame(data=_x, columns=_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LagValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, by):\n",
    "        self.by = by\n",
    "        self.created_features = None\n",
    "        \n",
    "    def transform(self, df_x):\n",
    "        columns_to_shift = [col for col in df_x.columns if col != self.by]\n",
    "        df_lags = df_x.sort_values(self.by, ascending=True)\n",
    "        df_lags.drop(self.by, axis=1, inplace=True)\n",
    "        df_lags = df_lags.shift(-1)\n",
    "        df_lags.columns = [f'{col}_shift_1' for col in columns_to_shift]\n",
    "        \n",
    "        if self.created_features is None:\n",
    "            self.created_features = list(df_lags.columns)\n",
    "        else:\n",
    "            assert self.created_features == list(df_lags.columns)\n",
    "        return df_lags\n",
    "        \n",
    "    def fit(self, x, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.created_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_transformer = ColumnTransformer([\n",
    "    (col, LagValues(by=col), [col] + numerical_columns) \n",
    "    for col in datetime_columns\n",
    "])\n",
    "\n",
    "# _x = lag_transformer.fit_transform(df_x)\n",
    "# _features = lag_transformer.get_feature_names()\n",
    "# pd.DataFrame(data=_x, columns=_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnsSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.created_features = None\n",
    "    \n",
    "    def transform(self, df_x):                \n",
    "        df_selected = df_x[self.columns].copy()\n",
    "        self.created_features = list(df_selected)\n",
    "        return df_selected\n",
    "    \n",
    "    def fit(self, x, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.created_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feature_generator = FeatureUnion([\n",
    "    ('numeric', ColumnsSelector(columns=numerical_columns)),\n",
    "    ('datetime', datetime_transformer),\n",
    "    ('lag_numeric', lag_transformer)\n",
    "], n_jobs=1)\n",
    "\n",
    "# feature_generator.fit_transform(df_x.head(1000))\n",
    "# feature_generator.transform(df_x.tail(1000))\n",
    "# feature_generator.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('feature_generator', feature_generator),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('model', RandomForestClassifier(n_jobs=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitrymikhailovich_/cnt/sdsj2018-automl/.direnv/python-3.6.3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, target, test_size=.33, random_state=123)\n",
    "# pipeline.fit(x_train, y_train)\n",
    "model = RandomForestClassifier().fit(pipeline.fit_transform(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8375851027875603"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pred = model.predict_proba(pipeline.transform(x_test))[:, 1]\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
